{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:19.426351Z","iopub.status.busy":"2024-06-16T07:22:19.425855Z","iopub.status.idle":"2024-06-16T07:22:23.613688Z","shell.execute_reply":"2024-06-16T07:22:23.612543Z","shell.execute_reply.started":"2024-06-16T07:22:19.426306Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Class 'positive': 750 instances\n","Class 'negative': 274 instances\n","Class 'neutral': 48 instances\n"]},{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at distilroberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at distilroberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","attention_mask (InputLayer)     [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","tf_roberta_model_1 (TFRobertaMo TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n","                                                                 attention_mask[0][0]             \n","__________________________________________________________________________________________________\n","global_average_pooling1d_1 (Glo (None, 768)          0           tf_roberta_model_1[0][0]         \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 3)            2307        global_average_pooling1d_1[0][0] \n","==================================================================================================\n","Total params: 82,120,707\n","Trainable params: 82,120,707\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras import optimizers, losses, Model\n","import tensorflow.keras.layers as L\n","from transformers import AutoTokenizer, TFAutoModel\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# Load datasets\n","\n","# training_df = pd.read_csv(\"/kaggle/input/sentiment-classification/SemEval14_res/Train/Restaurants_Train.csv\")\n","# validation_df = pd.read_csv(\"/kaggle/input/sentiment-classification/SemEval14_res/Test/Restaurants_Test.csv\")\n","\n","training_df = pd.read_csv(\"/kaggle/input/sentiment-classification/Spain_Res/Train/SemEval-2016ABSA Restaurants-Spanish_Train_Subtask1.csv\").astype(str)\n","validation_df = pd.read_csv(\"/kaggle/input/sentiment-classification/Spain_Res/Test/SP_REST_SB1_TEST.csv\").astype(str)\n","\n","# training_df = pd.read_csv(\"/kaggle/input/sentiment-classification/SemEval16/Train/Restaurants_Train.csv\")\n","# validation_df = pd.read_csv(\"/kaggle/input/sentiment-classification/SemEval16/Test/Restaurants_Test.csv\")\n","\n","# Drop 'conflict' polarity entries\n","training_df.drop(training_df[training_df['polarity'] == 'conflict'].index, inplace=True)\n","validation_df.drop(validation_df[validation_df['polarity'] == 'conflict'].index, inplace=True)\n","\n","# Prepare labels\n","y_train = pd.get_dummies(training_df['polarity']).values\n","y_valid = pd.get_dummies(validation_df['polarity']).values\n","\n","import pandas as pd\n","\n","# Assuming your DataFrame is named df\n","class_counts = validation_df['polarity'].value_counts()\n","\n","# Print class counts and their names\n","for class_name, count in class_counts.items():\n","    print(f\"Class '{class_name}': {count} instances\")\n","\n","\n","# # Initialization WordNetLemmatizer\n","# import re\n","# from nltk.stem import WordNetLemmatizer\n","# from bs4 import BeautifulSoup\n","# import emoji\n","# import string\n","# # Initialize the WordNetLemmatizer\n","# wnl = WordNetLemmatizer()\n","\n","# def preprocess_text(text):\n","#     \"\"\"\n","#     Performs a series of preprocessing steps on the input text.\n","#     Args:\n","#         text (str): The input text to be preprocessed.\n","#     Returns:\n","#         str: The preprocessed text.\n","#     \"\"\"\n","#     # Remove HTML tags using BeautifulSoup.\n","#     text = BeautifulSoup(text, \"html.parser\").get_text()\n","#     # Remove content within square brackets.\n","#     text = re.sub('\\[[^]]*\\]', '', text)\n","#     # Expand contractions.\n","#     #text = decontraction(text)\n","#     # Remove emojis.\n","#     #text = remove_emojis(text)\n","#     # Remove URLs, usernames, and similar patterns.\n","#     text = re.sub(r'https?://\\S+|www\\.\\S+|@[^\\s]+', '', text)\n","#     # Remove punctuation using a translation table.\n","#     text = text.translate(str.maketrans('', '', string.punctuation))\n","    \n","#     # Replace sequences of the same character where length > 2 with two characters.\n","#     #text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)\n","    \n","#     # Remove non-alphabetical characters.\n","#     text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n","#     # Convert to lowercase to normalize the text.\n","#     text = text.lower()\n","#     return text\n","\n","# # Note: This function now includes lemmatization in the preprocessing pipeline.\n","# # preprocess_text--- data cleaning with lemmatization\n","# training_df['Sentence'] = training_df['Sentence'].apply(preprocess_text)\n","# validation_df['Sentence'] = validation_df['Sentence'].apply(preprocess_text)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# Tokenizer and Transformer configuration\n","transformer_model = 'distilroberta-base'\n","tokenizer = AutoTokenizer.from_pretrained(transformer_model)\n","seq_len = 512  # Max sequence length\n","batch_size = 8\n","\n","# Function to emphasize aspect terms in sentences\n","def emphasize_aspect_terms(sentence, aspect):\n","    # Example strategy: Repeat the aspect term twice and wrap with special tokens\n","    emphasized_sentence = sentence.replace(aspect, f\"[ASP] {aspect} {aspect} [/ASP]\")\n","    return emphasized_sentence\n","\n","# Apply emphasis on aspect terms\n","training_df['Emphasized_Sentence'] = training_df.apply(lambda x: emphasize_aspect_terms(x['Sentence'], x['Aspect Term']), axis=1)\n","validation_df['Emphasized_Sentence'] = validation_df.apply(lambda x: emphasize_aspect_terms(x['Sentence'], x['Aspect Term']), axis=1)\n","\n","# Tokenization\n","tokenized_inputs_train = tokenizer(training_df['Emphasized_Sentence'].tolist(), max_length=seq_len, truncation=True, padding='max_length', return_tensors='tf')\n","tokenized_inputs_valid = tokenizer(validation_df['Emphasized_Sentence'].tolist(), max_length=seq_len, truncation=True, padding='max_length', return_tensors='tf')\n","\n","# Model Building\n","encoder = TFAutoModel.from_pretrained(transformer_model)\n","\n","input_ids = L.Input(shape=(seq_len,), dtype=tf.int32, name=\"input_ids\")\n","attention_mask = L.Input(shape=(seq_len,), dtype=tf.int32, name=\"attention_mask\")\n","embeddings = encoder(input_ids, attention_mask=attention_mask)[0]\n","pooled_output = L.GlobalAveragePooling1D()(embeddings)\n","outputs = L.Dense(y_train.shape[1], activation='softmax')(pooled_output)\n","\n","model = Model(inputs=[input_ids, attention_mask], outputs=outputs)\n","model.compile(optimizer=optimizers.Adam(learning_rate=1e-5), loss=losses.CategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n","\n","# Prepare TensorFlow datasets\n","train_dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': tokenized_inputs_train['input_ids'], 'attention_mask': tokenized_inputs_train['attention_mask']}, y_train))\n","valid_dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': tokenized_inputs_valid['input_ids'], 'attention_mask': tokenized_inputs_valid['attention_mask']}, y_valid))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:23.616543Z","iopub.status.busy":"2024-06-16T07:22:23.616071Z","iopub.status.idle":"2024-06-16T07:22:23.635853Z","shell.execute_reply":"2024-06-16T07:22:23.634736Z","shell.execute_reply.started":"2024-06-16T07:22:23.616499Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Sentence</th>\n","      <th>Aspect Term</th>\n","      <th>polarity</th>\n","      <th>from</th>\n","      <th>to</th>\n","      <th>Emphasized_Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>es_9reinas_10_JordiCollGranell_2014-09-21:0</td>\n","      <td>Nos sentimos muy a gusto.</td>\n","      <td>nan</td>\n","      <td>positive</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Nos sentimos muy a gusto.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>es_9reinas_10_JordiCollGranell_2014-09-21:1</td>\n","      <td>Buen servicio, ambiente Acogedor  y tranquilo,...</td>\n","      <td>servicio</td>\n","      <td>positive</td>\n","      <td>5</td>\n","      <td>13</td>\n","      <td>Buen [ASP] servicio servicio [/ASP], ambiente ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>es_9reinas_10_JordiCollGranell_2014-09-21:1</td>\n","      <td>Buen servicio, ambiente Acogedor  y tranquilo,...</td>\n","      <td>ambiente</td>\n","      <td>positive</td>\n","      <td>15</td>\n","      <td>23</td>\n","      <td>Buen servicio, [ASP] ambiente ambiente [/ASP] ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>es_9reinas_10_JordiCollGranell_2014-09-21:1</td>\n","      <td>Buen servicio, ambiente Acogedor  y tranquilo,...</td>\n","      <td>comida</td>\n","      <td>positive</td>\n","      <td>47</td>\n","      <td>53</td>\n","      <td>Buen servicio, ambiente Acogedor  y tranquilo,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>es_9reinas_10_JordiCollGranell_2014-09-21:2</td>\n","      <td>Muy recomendable</td>\n","      <td>nan</td>\n","      <td>positive</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Muy recomendable</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2715</th>\n","      <td>es_wok-aragonia-dinasty-zaragoza_comment-2372:13</td>\n","      <td>Creo que si espaciaran un poco las mesas y cam...</td>\n","      <td>restaurante</td>\n","      <td>negative</td>\n","      <td>130</td>\n","      <td>141</td>\n","      <td>Creo que si espaciaran un poco las mesas y cam...</td>\n","    </tr>\n","    <tr>\n","      <th>2716</th>\n","      <td>es_wok-aragonia-dinasty-zaragoza_comment-4800:0</td>\n","      <td>Pues francamente, es un sitio que no vale la p...</td>\n","      <td>sitio</td>\n","      <td>negative</td>\n","      <td>24</td>\n","      <td>29</td>\n","      <td>Pues francamente, es un [ASP] sitio sitio [/AS...</td>\n","    </tr>\n","    <tr>\n","      <th>2717</th>\n","      <td>es_wok-aragonia-dinasty-zaragoza_comment-4800:1</td>\n","      <td>Mucho cartel, muy moderno, mucho espacio, para...</td>\n","      <td>nan</td>\n","      <td>negative</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Mucho cartel, muy moderno, mucho espacio, para...</td>\n","    </tr>\n","    <tr>\n","      <th>2718</th>\n","      <td>es_wok-aragonia-dinasty-zaragoza_comment-4800:2</td>\n","      <td>Recomiendo encarecidamente optar por el Wok de...</td>\n","      <td>Wok</td>\n","      <td>positive</td>\n","      <td>40</td>\n","      <td>43</td>\n","      <td>Recomiendo encarecidamente optar por el [ASP] ...</td>\n","    </tr>\n","    <tr>\n","      <th>2719</th>\n","      <td>es_wok-aragonia-dinasty-zaragoza_comment-4800:3</td>\n","      <td>Bastante mejor en todo, y si no recuerdo mal i...</td>\n","      <td>nan</td>\n","      <td>positive</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Bastante mejor en todo, y si no recuerdo mal i...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2719 rows × 7 columns</p>\n","</div>"],"text/plain":["                                                    id  \\\n","0          es_9reinas_10_JordiCollGranell_2014-09-21:0   \n","1          es_9reinas_10_JordiCollGranell_2014-09-21:1   \n","2          es_9reinas_10_JordiCollGranell_2014-09-21:1   \n","3          es_9reinas_10_JordiCollGranell_2014-09-21:1   \n","4          es_9reinas_10_JordiCollGranell_2014-09-21:2   \n","...                                                ...   \n","2715  es_wok-aragonia-dinasty-zaragoza_comment-2372:13   \n","2716   es_wok-aragonia-dinasty-zaragoza_comment-4800:0   \n","2717   es_wok-aragonia-dinasty-zaragoza_comment-4800:1   \n","2718   es_wok-aragonia-dinasty-zaragoza_comment-4800:2   \n","2719   es_wok-aragonia-dinasty-zaragoza_comment-4800:3   \n","\n","                                               Sentence  Aspect Term  \\\n","0                             Nos sentimos muy a gusto.          nan   \n","1     Buen servicio, ambiente Acogedor  y tranquilo,...     servicio   \n","2     Buen servicio, ambiente Acogedor  y tranquilo,...     ambiente   \n","3     Buen servicio, ambiente Acogedor  y tranquilo,...       comida   \n","4                                      Muy recomendable          nan   \n","...                                                 ...          ...   \n","2715  Creo que si espaciaran un poco las mesas y cam...  restaurante   \n","2716  Pues francamente, es un sitio que no vale la p...        sitio   \n","2717  Mucho cartel, muy moderno, mucho espacio, para...          nan   \n","2718  Recomiendo encarecidamente optar por el Wok de...          Wok   \n","2719  Bastante mejor en todo, y si no recuerdo mal i...          nan   \n","\n","      polarity from   to                                Emphasized_Sentence  \n","0     positive    0    0                          Nos sentimos muy a gusto.  \n","1     positive    5   13  Buen [ASP] servicio servicio [/ASP], ambiente ...  \n","2     positive   15   23  Buen servicio, [ASP] ambiente ambiente [/ASP] ...  \n","3     positive   47   53  Buen servicio, ambiente Acogedor  y tranquilo,...  \n","4     positive    0    0                                   Muy recomendable  \n","...        ...  ...  ...                                                ...  \n","2715  negative  130  141  Creo que si espaciaran un poco las mesas y cam...  \n","2716  negative   24   29  Pues francamente, es un [ASP] sitio sitio [/AS...  \n","2717  negative    0    0  Mucho cartel, muy moderno, mucho espacio, para...  \n","2718  positive   40   43  Recomiendo encarecidamente optar por el [ASP] ...  \n","2719  positive    0    0  Bastante mejor en todo, y si no recuerdo mal i...  \n","\n","[2719 rows x 7 columns]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["training_df"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:23.637360Z","iopub.status.busy":"2024-06-16T07:22:23.637049Z","iopub.status.idle":"2024-06-16T07:22:23.647688Z","shell.execute_reply":"2024-06-16T07:22:23.646677Z","shell.execute_reply.started":"2024-06-16T07:22:23.637331Z"},"trusted":true},"outputs":[],"source":["# import numpy as np\n","# import pandas as pd\n","# import tensorflow as tf\n","# from tensorflow.keras import optimizers, losses, Model\n","# import tensorflow.keras.layers as L\n","# from transformers import AutoTokenizer, TFAutoModel\n","# from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# # Load datasets\n","\n","# training_df = pd.read_csv(\"/kaggle/input/sentiment-classification/SemEval14_res/Train/Restaurants_Train.csv\")\n","# validation_df = pd.read_csv(\"/kaggle/input/sentiment-classification/SemEval14_res/Test/Restaurants_Test.csv\")\n","\n","# # training_df = pd.read_csv(\"/kaggle/input/sentiment-classification/SemEval15/Train/Restaurants_Train.csv\")\n","# # validation_df = pd.read_csv(\"/kaggle/input/sentiment-classification/SemEval15/Test/Restaurants_Test.csv\")\n","\n","# # training_df = pd.read_csv(\"/kaggle/input/sentiment-classification/SemEval16/Train/Restaurants_Train.csv\")\n","# # validation_df = pd.read_csv(\"/kaggle/input/sentiment-classification/SemEval16/Test/Restaurants_Test.csv\")\n","\n","# # training_df = pd.read_csv(\"/kaggle/input/sentiment-classification/Sentihood/Train/Sentihood_train.csv\")\n","# # validation_df = pd.read_csv(\"/kaggle/input/sentiment-classification/Sentihood/Test/Sentihood_test.csv\")\n","\n","\n","# # Drop 'conflict' polarity entries\n","# training_df.drop(training_df[training_df['polarity'] == 'conflict'].index, inplace=True)\n","# validation_df.drop(validation_df[validation_df['polarity'] == 'conflict'].index, inplace=True)\n","\n","# # Prepare labels\n","# y_train = pd.get_dummies(training_df['polarity']).values\n","# y_valid = pd.get_dummies(validation_df['polarity']).values\n","\n","# import pandas as pd\n","\n","# # Assuming your DataFrame is named df\n","# class_counts = training_df['polarity'].value_counts()\n","\n","# # Print class counts and their names\n","# for class_name, count in class_counts.items():\n","#     print(f\"Class '{class_name}': {count} instances\")\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:23.650989Z","iopub.status.busy":"2024-06-16T07:22:23.650634Z","iopub.status.idle":"2024-06-16T07:22:23.660804Z","shell.execute_reply":"2024-06-16T07:22:23.659788Z","shell.execute_reply.started":"2024-06-16T07:22:23.650959Z"},"trusted":true},"outputs":[],"source":["# from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# # Define a checkpoint callback\n","# checkpoint_path = \"/kaggle/working/best_model_tr.h5\"\n","# checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","\n","# # Training\n","# model.fit(train_dataset.shuffle(10000).batch(batch_size), \n","#           validation_data=valid_dataset.batch(batch_size), \n","#           epochs=10,\n","#           verbose=1,\n","#           callbacks=[checkpoint])  # Add checkpoint callback\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:23.662427Z","iopub.status.busy":"2024-06-16T07:22:23.662099Z","iopub.status.idle":"2024-06-16T07:22:23.672495Z","shell.execute_reply":"2024-06-16T07:22:23.671605Z","shell.execute_reply.started":"2024-06-16T07:22:23.662397Z"},"trusted":true},"outputs":[],"source":["# from transformers import TFRobertaModel  # Import the necessary layer\n","# from tensorflow.keras.models import load_model\n","\n","# # Load the model with custom objects argument\n","# custom_objects = {'TFRobertaModel': TFRobertaModel}\n","# model = load_model(\"/kaggle/working/best_model_tr.h5\", custom_objects=custom_objects)\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:23.673957Z","iopub.status.busy":"2024-06-16T07:22:23.673653Z","iopub.status.idle":"2024-06-16T07:22:45.238867Z","shell.execute_reply":"2024-06-16T07:22:45.237869Z","shell.execute_reply.started":"2024-06-16T07:22:23.673928Z"},"trusted":true},"outputs":[],"source":["# Making predictions on the validation dataset\n","y_pred = model.predict(valid_dataset.batch(batch_size))"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:45.240621Z","iopub.status.busy":"2024-06-16T07:22:45.240272Z","iopub.status.idle":"2024-06-16T07:22:45.246426Z","shell.execute_reply":"2024-06-16T07:22:45.245278Z","shell.execute_reply.started":"2024-06-16T07:22:45.240587Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1072, 3)\n"]}],"source":["print(y_pred.shape)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:45.248141Z","iopub.status.busy":"2024-06-16T07:22:45.247791Z","iopub.status.idle":"2024-06-16T07:22:45.263327Z","shell.execute_reply":"2024-06-16T07:22:45.262280Z","shell.execute_reply.started":"2024-06-16T07:22:45.248096Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["F1 Score: 0.10406178616575369\n","Precision: 0.06532983403876141\n","Recall: 0.2555970149253731\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["from sklearn.metrics import f1_score\n","from sklearn.metrics import cohen_kappa_score, precision_score, recall_score\n","\n","\n","# Converting probabili৮ties to class labels\n","y_pred_labels = np.argmax(y_pred, axis=1)\n","y_true_labels = np.argmax(y_valid, axis=1)\n","\n","\n","# Computing F1 score\n","f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n","print(\"F1 Score:\", f1)\n","\n","# Computing precision\n","precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n","print(\"Precision:\", precision)\n","\n","# Computing recall\n","recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n","print(\"Recall:\", recall)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:45.264925Z","iopub.status.busy":"2024-06-16T07:22:45.264587Z","iopub.status.idle":"2024-06-16T07:22:45.269595Z","shell.execute_reply":"2024-06-16T07:22:45.268422Z","shell.execute_reply.started":"2024-06-16T07:22:45.264879Z"},"trusted":true},"outputs":[],"source":["# F1 Score: 0.7940415317576729\n","# Precision: 0.799109346633389\n","# Recall: 0.7978056426332288"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:45.275402Z","iopub.status.busy":"2024-06-16T07:22:45.275056Z","iopub.status.idle":"2024-06-16T07:22:45.294457Z","shell.execute_reply":"2024-06-16T07:22:45.293479Z","shell.execute_reply.started":"2024-06-16T07:22:45.275371Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_4\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","attention_mask (InputLayer)     [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","tf_roberta_model_1 (TFRobertaMo TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n","                                                                 attention_mask[0][0]             \n","__________________________________________________________________________________________________\n","global_average_pooling1d_1 (Glo (None, 768)          0           tf_roberta_model_1[0][0]         \n","==================================================================================================\n","Total params: 82,118,400\n","Trainable params: 82,118,400\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# Access the layers of the model\n","layers = model.layers\n","output_tensor = layers[-2].output\n","new_model = Model(inputs=model.input, outputs=output_tensor)\n","new_model.summary()"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:45.296080Z","iopub.status.busy":"2024-06-16T07:22:45.295711Z","iopub.status.idle":"2024-06-16T07:22:45.302102Z","shell.execute_reply":"2024-06-16T07:22:45.300908Z","shell.execute_reply.started":"2024-06-16T07:22:45.296052Z"},"trusted":true},"outputs":[],"source":["# # Making predictions on the validation dataset\n","# y_pred = new_model.predict(valid_dataset.batch(batch_size))\n","# print(y_pred.shape)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:22:45.303768Z","iopub.status.busy":"2024-06-16T07:22:45.303437Z","iopub.status.idle":"2024-06-16T07:23:58.183301Z","shell.execute_reply":"2024-06-16T07:23:58.182377Z","shell.execute_reply.started":"2024-06-16T07:22:45.303738Z"},"trusted":true},"outputs":[],"source":["new_traning_data=new_model.predict(train_dataset.batch(batch_size))\n","new_valid_dataset=new_model.predict(valid_dataset.batch(batch_size))"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:23:58.184859Z","iopub.status.busy":"2024-06-16T07:23:58.184538Z","iopub.status.idle":"2024-06-16T07:23:58.189954Z","shell.execute_reply":"2024-06-16T07:23:58.188970Z","shell.execute_reply.started":"2024-06-16T07:23:58.184830Z"},"trusted":true},"outputs":[],"source":["# from sklearn.svm import SVC\n","# from sklearn.metrics import f1_score\n","\n","# # Assuming new_traning_data and new_valid_dataset are features extracted by your neural network\n","# # and train_labels, valid_labels are the corresponding labels\n","# svm = SVC(kernel='rbf')  # You can choose different kernels like 'rbf', 'poly', etc.\n","\n","# # Reshape the data if necessary\n","# new_traning_data = new_traning_data.reshape(new_traning_data.shape[0], -1)\n","# new_valid_dataset = new_valid_dataset.reshape(new_valid_dataset.shape[0], -1)\n","# y_train_single = np.argmax(y_train, axis=1)\n","\n","# # Train the SVM\n","# svm.fit(new_traning_data, y_train_single)\n","\n","# # Evaluate the SVM on the validation dataset\n","# svm_predictions = svm.predict(new_valid_dataset)\n","# y_valid_single = np.argmax(y_valid, axis=1)\n","# # Calculate F1 score\n","# f1 = f1_score(y_valid_single, svm_predictions, average='micro')\n","\n","# print(\"SVM F1 Score on validation dataset:\", f1)\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:23:58.191607Z","iopub.status.busy":"2024-06-16T07:23:58.191226Z","iopub.status.idle":"2024-06-16T07:23:58.198948Z","shell.execute_reply":"2024-06-16T07:23:58.198084Z","shell.execute_reply.started":"2024-06-16T07:23:58.191573Z"},"trusted":true},"outputs":[],"source":["# from sklearn.metrics import confusion_matrix\n","# import seaborn as sns\n","# import matplotlib.pyplot as plt\n","\n","# # Compute confusion matrix\n","# conf_matrix = confusion_matrix(y_valid_single, svm_predictions)\n","\n","# plt.figure(figsize=(10, 8))\n","# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 18}) # Set annotation font size\n","# plt.xlabel('Predicted labels', fontsize=18) # Set x-axis label font size\n","# plt.ylabel('True labels', fontsize=18) # Set y-axis label font size\n","# plt.title('Confusion Matrix', fontsize=20) # Set title font size\n","# plt.xticks(fontsize=18) # Set x-axis tick font size\n","# plt.yticks(fontsize=18) # Set y-axis tick font size\n","# plt.show()\n"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:23:58.200550Z","iopub.status.busy":"2024-06-16T07:23:58.200240Z","iopub.status.idle":"2024-06-16T07:24:10.093410Z","shell.execute_reply":"2024-06-16T07:24:10.092234Z","shell.execute_reply.started":"2024-06-16T07:23:58.200516Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: stellargraph in /opt/conda/lib/python3.7/site-packages (1.2.1)\n","Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from stellargraph) (1.7.3)\n","Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from stellargraph) (2.5)\n","Requirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.7/site-packages (from stellargraph) (1.3.5)\n","Requirement already satisfied: tensorflow>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from stellargraph) (2.6.4)\n","Requirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.7/site-packages (from stellargraph) (1.19.5)\n","Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.7/site-packages (from stellargraph) (3.5.2)\n","Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/lib/python3.7/site-packages (from stellargraph) (1.0.2)\n","Requirement already satisfied: gensim>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from stellargraph) (4.0.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim>=3.4.0->stellargraph) (5.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->stellargraph) (2.8.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->stellargraph) (21.3)\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->stellargraph) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->stellargraph) (1.4.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->stellargraph) (4.33.3)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->stellargraph) (9.1.1)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->stellargraph) (0.11.0)\n","Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->stellargraph) (5.1.1)\n","Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24->stellargraph) (2022.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20->stellargraph) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20->stellargraph) (1.1.0)\n","Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (0.15.0)\n","Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (2.6.0)\n","Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (0.2.0)\n","Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (0.4.0)\n","Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (0.37.1)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (3.3.0)\n","Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (2.6.0)\n","Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (1.15.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (1.1.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (3.20.1)\n","Requirement already satisfied: typing-extensions<3.11,>=3.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (3.10.0.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (1.12.1)\n","Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (3.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (1.43.0)\n","Requirement already satisfied: keras<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (2.6.0)\n","Requirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (5.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (1.1.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (1.12)\n","Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->stellargraph) (1.6.3)\n","Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow>=2.1.0->stellargraph) (1.5.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (1.35.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (2.27.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (2.1.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (3.3.7)\n","Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (59.8.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (0.2.7)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (4.11.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (2022.6.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (3.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (1.26.9)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow>=2.1.0->stellargraph) (3.2.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install stellargraph"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:24:10.095479Z","iopub.status.busy":"2024-06-16T07:24:10.095090Z","iopub.status.idle":"2024-06-16T07:24:10.103676Z","shell.execute_reply":"2024-06-16T07:24:10.102519Z","shell.execute_reply.started":"2024-06-16T07:24:10.095441Z"},"trusted":true},"outputs":[],"source":["X, y = np.concatenate((new_traning_data, new_valid_dataset), axis=0), np.concatenate((y_train, y_valid), axis=0)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:24:10.105722Z","iopub.status.busy":"2024-06-16T07:24:10.105320Z","iopub.status.idle":"2024-06-16T07:24:10.113389Z","shell.execute_reply":"2024-06-16T07:24:10.112142Z","shell.execute_reply.started":"2024-06-16T07:24:10.105682Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(2719, 768)\n","(1072, 768)\n"]}],"source":["print(new_traning_data.shape)\n","print(new_valid_dataset.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:24:10.115668Z","iopub.status.busy":"2024-06-16T07:24:10.115221Z","iopub.status.idle":"2024-06-16T07:24:10.318819Z","shell.execute_reply":"2024-06-16T07:24:10.317817Z","shell.execute_reply.started":"2024-06-16T07:24:10.115633Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_5 (InputLayer)            [(None, 10, 768)]    0                                            \n","__________________________________________________________________________________________________\n","input_6 (InputLayer)            [(None, 50, 768)]    0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, 1, 768)]     0                                            \n","__________________________________________________________________________________________________\n","reshape_4 (Reshape)             (None, 1, 10, 768)   0           input_5[0][0]                    \n","__________________________________________________________________________________________________\n","reshape_5 (Reshape)             (None, 10, 5, 768)   0           input_6[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_45 (Dropout)            (None, 1, 768)       0           input_4[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_44 (Dropout)            (None, 1, 10, 768)   0           reshape_4[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_47 (Dropout)            (None, 10, 768)      0           input_5[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_46 (Dropout)            (None, 10, 5, 768)   0           reshape_5[0][0]                  \n","__________________________________________________________________________________________________\n","mean_aggregator_2 (MeanAggregat multiple             49216       dropout_45[0][0]                 \n","                                                                 dropout_44[0][0]                 \n","                                                                 dropout_47[0][0]                 \n","                                                                 dropout_46[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_6 (Reshape)             (None, 1, 10, 64)    0           mean_aggregator_2[1][0]          \n","__________________________________________________________________________________________________\n","dropout_49 (Dropout)            (None, 1, 64)        0           mean_aggregator_2[0][0]          \n","__________________________________________________________________________________________________\n","dropout_48 (Dropout)            (None, 1, 10, 64)    0           reshape_6[0][0]                  \n","__________________________________________________________________________________________________\n","mean_aggregator_3 (MeanAggregat (None, 1, 32)        2080        dropout_49[0][0]                 \n","                                                                 dropout_48[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_7 (Reshape)             (None, 32)           0           mean_aggregator_3[0][0]          \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 32)           0           reshape_7[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 3)            99          lambda_1[0][0]                   \n","==================================================================================================\n","Total params: 51,395\n","Trainable params: 51,395\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["import stellargraph as sg\n","from stellargraph.layer import GraphSAGE\n","from stellargraph.mapper import GraphSAGENodeGenerator\n","from tensorflow.keras import layers, models\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","df = pd.DataFrame(X)\n","\n","# Construct a graph from the DataFrame\n","graph = sg.StellarGraph(nodes=df)\n","\n","# Split the data into training, validation, and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(df.index, y, test_size=0.2160, shuffle=False)\n","\n","\n","\n","# Define the GraphSAGE model\n","generator = GraphSAGENodeGenerator(graph, batch_size=8, num_samples=[10, 5])\n","train_gen = generator.flow(X_train, y_train)\n","\n","graphsage_model = GraphSAGE(\n","    layer_sizes=[64, 32],\n","    generator=generator,\n","    bias=True,\n","    dropout=0.2,\n","    normalize=\"l2\"\n",")\n","\n","# Build the model\n","x_inp, x_out = graphsage_model.in_out_tensors()\n","prediction = layers.Dense(units=3, activation=\"softmax\")(x_out)\n","\n","model = models.Model(inputs=x_inp, outputs=prediction)\n","learning_rate = 0.001  # Set your desired learning rate here\n","\n","optimizer = optimizers.Adam(learning_rate=learning_rate)\n","model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n","model.summary()\n","\n","\n","# Define a checkpoint callback\n","checkpoint_path = \"/kaggle/working/best_model_gnn.h5\"\n","checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True)\n","\n"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:24:10.320894Z","iopub.status.busy":"2024-06-16T07:24:10.320500Z","iopub.status.idle":"2024-06-16T07:26:04.607746Z","shell.execute_reply":"2024-06-16T07:26:04.606720Z","shell.execute_reply.started":"2024-06-16T07:24:10.320854Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","372/372 [==============================] - 3s 7ms/step - loss: 0.7672 - acc: 0.6941 - val_loss: 0.7165 - val_acc: 0.7070\n","Epoch 2/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.7185 - acc: 0.7049 - val_loss: 0.6994 - val_acc: 0.7070\n","Epoch 3/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.7039 - acc: 0.7029 - val_loss: 0.6980 - val_acc: 0.7070\n","Epoch 4/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6876 - acc: 0.7012 - val_loss: 0.6707 - val_acc: 0.7131\n","Epoch 5/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6859 - acc: 0.7069 - val_loss: 0.6705 - val_acc: 0.7070\n","Epoch 6/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6844 - acc: 0.7063 - val_loss: 0.6516 - val_acc: 0.7192\n","Epoch 7/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6705 - acc: 0.7076 - val_loss: 0.6574 - val_acc: 0.7094\n","Epoch 8/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6549 - acc: 0.7241 - val_loss: 0.6470 - val_acc: 0.7179\n","Epoch 9/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6481 - acc: 0.7248 - val_loss: 0.6244 - val_acc: 0.7302\n","Epoch 10/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6418 - acc: 0.7416 - val_loss: 0.7432 - val_acc: 0.7179\n","Epoch 11/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6456 - acc: 0.7406 - val_loss: 0.6107 - val_acc: 0.7582\n","Epoch 12/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6298 - acc: 0.7402 - val_loss: 0.6069 - val_acc: 0.7509\n","Epoch 13/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6294 - acc: 0.7416 - val_loss: 0.6479 - val_acc: 0.7326\n","Epoch 14/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6361 - acc: 0.7392 - val_loss: 0.6019 - val_acc: 0.7570\n","Epoch 15/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6217 - acc: 0.7450 - val_loss: 0.5953 - val_acc: 0.7521\n","Epoch 16/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6244 - acc: 0.7510 - val_loss: 0.6064 - val_acc: 0.7546\n","Epoch 17/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6233 - acc: 0.7433 - val_loss: 0.6123 - val_acc: 0.7424\n","Epoch 18/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6136 - acc: 0.7483 - val_loss: 0.5937 - val_acc: 0.7521\n","Epoch 19/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6230 - acc: 0.7386 - val_loss: 0.6551 - val_acc: 0.7411\n","Epoch 20/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6269 - acc: 0.7436 - val_loss: 0.5856 - val_acc: 0.7521\n","Epoch 21/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6257 - acc: 0.7349 - val_loss: 0.5995 - val_acc: 0.7521\n","Epoch 22/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6093 - acc: 0.7473 - val_loss: 0.5925 - val_acc: 0.7582\n","Epoch 23/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6175 - acc: 0.7473 - val_loss: 0.5960 - val_acc: 0.7582\n","Epoch 24/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6136 - acc: 0.7487 - val_loss: 0.5940 - val_acc: 0.7473\n","Epoch 25/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6089 - acc: 0.7530 - val_loss: 0.5894 - val_acc: 0.7595\n","Epoch 26/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6106 - acc: 0.7463 - val_loss: 0.6142 - val_acc: 0.7363\n","Epoch 27/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6107 - acc: 0.7577 - val_loss: 0.6295 - val_acc: 0.7399\n","Epoch 28/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6106 - acc: 0.7550 - val_loss: 0.6571 - val_acc: 0.7326\n","Epoch 29/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6204 - acc: 0.7409 - val_loss: 0.6004 - val_acc: 0.7473\n","Epoch 30/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.5976 - acc: 0.7574 - val_loss: 0.6778 - val_acc: 0.7350\n","Epoch 31/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6041 - acc: 0.7534 - val_loss: 0.5860 - val_acc: 0.7473\n","Epoch 32/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6000 - acc: 0.7604 - val_loss: 0.6079 - val_acc: 0.7424\n","Epoch 33/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6018 - acc: 0.7577 - val_loss: 0.6033 - val_acc: 0.7668\n","Epoch 34/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.5961 - acc: 0.7584 - val_loss: 0.5931 - val_acc: 0.7460\n","Epoch 35/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.5999 - acc: 0.7571 - val_loss: 0.6335 - val_acc: 0.7399\n","Epoch 36/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6035 - acc: 0.7688 - val_loss: 0.5920 - val_acc: 0.7485\n","Epoch 37/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6107 - acc: 0.7561 - val_loss: 0.5851 - val_acc: 0.7460\n","Epoch 38/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6031 - acc: 0.7520 - val_loss: 0.5876 - val_acc: 0.7460\n","Epoch 39/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6017 - acc: 0.7527 - val_loss: 0.6029 - val_acc: 0.7509\n","Epoch 40/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6017 - acc: 0.7530 - val_loss: 0.6669 - val_acc: 0.7375\n","Epoch 41/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6026 - acc: 0.7557 - val_loss: 0.5832 - val_acc: 0.7521\n","Epoch 42/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.5964 - acc: 0.7688 - val_loss: 0.5828 - val_acc: 0.7509\n","Epoch 43/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.5892 - acc: 0.7631 - val_loss: 0.5945 - val_acc: 0.7424\n","Epoch 44/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.5912 - acc: 0.7574 - val_loss: 0.6067 - val_acc: 0.7424\n","Epoch 45/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.6036 - acc: 0.7584 - val_loss: 0.6056 - val_acc: 0.7473\n","Epoch 46/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.5892 - acc: 0.7631 - val_loss: 0.6246 - val_acc: 0.7363\n","Epoch 47/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.5915 - acc: 0.7550 - val_loss: 0.5874 - val_acc: 0.7448\n","Epoch 48/50\n","372/372 [==============================] - 2s 7ms/step - loss: 0.5880 - acc: 0.7611 - val_loss: 0.5820 - val_acc: 0.7485\n","Epoch 49/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.5878 - acc: 0.7662 - val_loss: 0.6314 - val_acc: 0.7436\n","Epoch 50/50\n","372/372 [==============================] - 2s 6ms/step - loss: 0.5854 - acc: 0.7675 - val_loss: 0.5773 - val_acc: 0.7680\n","103/103 [==============================] - 0s 4ms/step - loss: 0.5773 - acc: 0.7680\n","Test accuracy: 0.7680097818374634\n","F1 Score: 0.7486793055621129\n","Precision: 0.7311463664364375\n","Recall: 0.7680097680097681\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["# Train the model using the generator\n","history = model.fit(train_gen,\n","                    epochs=50,\n","                    validation_data=generator.flow(X_test, y_test),\n","                    verbose=1,\n","                    callbacks=[checkpoint])  # Add checkpoint callback\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(generator.flow(X_test, y_test))\n","print('Test accuracy:', test_acc)\n","\n","# Making predictions on the validation dataset\n","y_pred = model.predict(generator.flow(X_test, y_test))\n","\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import cohen_kappa_score, precision_score, recall_score\n","\n","\n","# Converting probabilities to class labels\n","y_pred_labels = np.argmax(y_pred, axis=1)\n","y_true_labels = np.argmax(y_test, axis=1)\n","\n","\n","# Computing F1 score\n","f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n","print(\"F1 Score:\", f1)\n","\n","# Computing precision\n","precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n","print(\"Precision:\", precision)\n","\n","# Computing recall\n","recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n","print(\"Recall:\", recall)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:26:04.609436Z","iopub.status.busy":"2024-06-16T07:26:04.609079Z","iopub.status.idle":"2024-06-16T07:26:04.623599Z","shell.execute_reply":"2024-06-16T07:26:04.622418Z","shell.execute_reply.started":"2024-06-16T07:26:04.609403Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["F1 Score: 0.7486793055621129\n","Precision: 0.7311463664364375\n","Recall: 0.7680097680097681\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["from sklearn.metrics import f1_score\n","from sklearn.metrics import cohen_kappa_score, precision_score, recall_score\n","\n","\n","# Converting probabilities to class labels\n","y_pred_labels = np.argmax(y_pred, axis=1)\n","y_true_labels = np.argmax(y_test, axis=1)\n","\n","\n","# Computing F1 score\n","f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n","print(\"F1 Score:\", f1)\n","\n","# Computing precision\n","precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n","print(\"Precision:\", precision)\n","\n","# Computing recall\n","recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n","print(\"Recall:\", recall)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4451489,"sourceId":8702619,"sourceType":"datasetVersion"}],"dockerImageVersionId":30203,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
